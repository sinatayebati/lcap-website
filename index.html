<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Unraveling Cross-Modality Knowledge Conflicts in Large Vision-Language Models">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Unraveling Cross-Modality Knowledge Conflicts in Large Vision-Language Models</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Unraveling Cross-Modality Knowledge Conflicts in Large Vision-Language Models</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://darthzhu.github.io/" target="_blank">Tinghui Zhu</a><sup>1</sup>&emsp;
              </span>
              <span class="author-block">
                <a href="https://qinliu9.github.io/" target="_blank">Qin Liu</a><sup>2</sup>&emsp;
              </span>
              <span class="author-block">
                <a href="https://feiwang96.github.io/" target="_blank">Fei Wang</a><sup>3</sup>&emsp;
              </span>
              <span class="author-block">
                <a href="https://vztu.github.io/" target="_blank">Zhengzhong Tu</a><sup>4</sup>&emsp;
              </span>
              <span class="author-block">
                <a href="https://muhaochen.github.io/" target="_blank">Muhao Chen</a><sup>2</sup>
              </span>
            </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                      <sup>1</sup>Fudan University&emsp;
                      <sup>2</sup>University of California, Davis<br>
                      <sup>3</sup>University of Southern California&emsp;
                      <sup>4</sup>Texas A&M University
                      <!-- <br>Conferance name and year -->
                    </span>
                    <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2410.03659" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/luka-group/vlm-knowledge-conflict" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2410.03659" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            While Large Vision-Language Models (LVLMs) have demonstrated impressive capabilities for capturing and reasoning over multimodal inputs, they are prone to parametric knowledge conflicts, which arise from inconsistencies of represented knowledge between their vision and language components.
            In this paper, we formally define the problem of <b>cross-modality parametric knowledge conflict</b> and present a systematic approach to detect, interpret, and mitigate them.
            We introduce a pipeline that identifies conflicts between visual and textual answers, showing a persistently high conflict rate across modalities in recent LVLMs regardless of the model size.
            We further investigate how these conflicts interfere with the inference process and propose a contrastive metric to discern the conflicting samples from the others.
            Building on these insights, we develop a novel dynamic contrastive decoding method that removes undesirable logits inferred from the less confident modality components based on answer confidence. 
            For models that do not provide logits, we also introduce two prompt-based strategies to mitigate the conflicts.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Detecting Parametric Knowledge Conflicts</h2>
        <div class="content has-text-justified">
          <img src="static/images/conflict_case.png" height="100%"/>
          <!-- <h2 class="subtitle has-text-centered">
            Example of cross-modality knowledge conflict.
          </h2> -->
          <p>
            For a question towards a named entity, we present the entity in both textual and visual form.
            For the textual form, we add a indicator prompt before the question, informing the model of the entity.
            For the visual form, we use an image depicting the entity.
            Then, we elicit the textual and visual answer from the model and compare to each other.
          </p>
          <img src="static/images/results_detect.png" height="100%"/>
          <!-- <h2 class="subtitle has-text-centered">
            Results of detecting cross-modality parametric knowledge conflicts.
          </h2> -->
          <p>
            There is a clear trend that as the model size increases, both the FR and the Î”Acc between textual and visual answers decrease.
            However, the lower bound of the knowledge conflict rate (CR) remains consistently high.
            This suggests that although scaling up models can enhance their overall performance and consistency, it does not resolve cross-modality knowledge conflicts.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Interpretating Parametric Knowledge Conflicts</h2>
        <div class="content has-text-justified">
          <img src="static/images/results_cd_metric.png" height="100%"/>
          <!-- <h2 class="subtitle has-text-centered">
            Distribution of the contrastive metric on all samples, samples with modality-consistent answers, and samples with modality-conflict answers. The dashed lines indicate the medians.
          </h2> -->
          <p>
            Confidence alone is not a reliable indicator of answer correctness when confronted with conflict samples.
            The proposed contrastive metric effectively distinguishes conflicting samples from consistent ones, suggesting that cross-modality knowledge conflicts tend to exacerbate the information gap between tokens across different modalities, regardless of the model size.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Mitigating Parametric Knowledge Conflicts</h2>
        <div class="content has-text-justified">
          <p>
            To mitigate cross-modality knowledge conflicts, we propose a dynamic contrastive decoding (DCD) method.
            For models that do not provide access to logits, we provide two prompting strategies.
          </p>
          <div class="container">
            <div id="results-carousel" class="carousel results-carousel">
             <div class="item">
                <img src="static/images/results_cd.png" height="100%" alt="MY ALT TEXT"/>
                <h2 class="subtitle has-text-centered">
                  Results of the dynamic contrastive decoding compared to the baselines.
                </h2>
              </div>
              <div class="item">
                <img src="static/images/results_prompt.png" height="100%" alt="MY ALT TEXT"/>
                <h2 class="subtitle has-text-centered">
                  Results of the prompt-based strategies compared to the baselines.
                </h2>
              </div>
            </div>
          </div>
          <p>
            Dynamic contrastive decoding (DCD) brings universal improvements against the baselines.
            The performance of prompting-based strategies varies depending on the model size.
            Larger models are better at understanding and processing the information in the designed prompts.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Image carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <img src="static/images/carousel1.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          First image description.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/carousel2.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Second image description.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/carousel3.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Third image description.
       </h2>
     </div>
     <div class="item">
      <img src="static/images/carousel4.jpg" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Fourth image description.
      </h2>
    </div>
  </div>
</div>
</div>
</section> -->
<!-- End image carousel -->

<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{zhu2024unraveling,
      title={Unraveling Cross-Modality Knowledge Conflict in Large Vision-Language Models},
      author={Zhu, Tinghui and Liu, Qin and Wang, Fei and Tu, Zhengzhong and Chen, Muhao},
      journal={arXiv preprint arXiv:2410.03659},
      year={2024}
    }</code></pre>
  </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from theÂ <a href="https://nerfies.github.io" target="_blank">Nerfies</a>Â project page.
            <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
